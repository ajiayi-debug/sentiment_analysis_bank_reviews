{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, AutoModelForCausalLM, TrainingArguments, Trainer, pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     'user': 'root',\n",
    "#     'password': 'JJY#91296517',\n",
    "#     'host': '127.0.0.1',\n",
    "#     'database': 'database',\n",
    "# }\n",
    "\n",
    "# # Establish a connection\n",
    "# cnx = mysql.connector.connect(**config)\n",
    "\n",
    "# # Define your query\n",
    "# query = f\"SELECT * FROM combined_reviews\"\n",
    "\n",
    "# # Use pandas to load sql query into a DataFrame\n",
    "# reviews = pd.read_sql(query, con=cnx)\n",
    "\n",
    "# print(reviews.head())  # Print the first few rows of the DataFrame\n",
    "\n",
    "# # Don't forget to close the connection when done\n",
    "# cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('combined_reviews.csv', index_col=0)\n",
    "reviews = reviews.drop(columns=['score', 'thumbsUpCount'])\n",
    "reviews = reviews.dropna()\n",
    "inst = 'Below is a review for a banking app. Write a response that appropriately replies to the review from the perspective of the bank.'\n",
    "text = []\n",
    "for index, row in reviews.iterrows():\n",
    "    text.append(f'{inst} ### Review: {row[\"content\"]} ### Reply: {row[\"replyContent\"]}')\n",
    "reviews['text'] = text\n",
    "reviews = Dataset.from_pandas(reviews)\n",
    "reviews = reviews.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['replyContent', 'content', 'text', '__index_level_0__'],\n",
       "        num_rows: 179\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['replyContent', 'content', 'text', '__index_level_0__'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'replyContent': \"We're delighted to receive your 5-star rating and appreciate your feedback! üëç Thank you for continued support in using our app! üíú\",\n",
       " 'content': 'Easy of use',\n",
       " 'text': \"Below is a review for a banking app. Write a response that appropriately replies to the review from the perspective of the bank. ### Review: Easy of use ### Reply: We're delighted to receive your 5-star rating and appreciate your feedback! üëç Thank you for continued support in using our app! üíú\",\n",
       " '__index_level_0__': 64}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model = \"distilbert/distilgpt2\"\n",
    "baseline_model = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 179/179 [00:00<00:00, 8364.03 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 5552.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_reviews = reviews.map(preprocess_function, batched=True, remove_columns=reviews['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 179\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeeda/Library/Python/3.9/lib/python/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "                                               \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 23/69 [00:36<01:17,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3148837089538574, 'eval_runtime': 1.5808, 'eval_samples_per_second': 12.652, 'eval_steps_per_second': 1.898, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 46/69 [01:05<00:25,  1.09s/it]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 46/69 [01:05<00:25,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.042876958847046, 'eval_runtime': 0.736, 'eval_samples_per_second': 27.173, 'eval_steps_per_second': 4.076, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:34<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9908866882324219, 'eval_runtime': 0.716, 'eval_samples_per_second': 27.934, 'eval_steps_per_second': 4.19, 'epoch': 3.0}\n",
      "{'train_runtime': 94.8694, 'train_samples_per_second': 5.66, 'train_steps_per_second': 0.727, 'train_loss': 2.591305276621943, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./gpt_model_causallm\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_path,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_reviews[\"train\"],\n",
    "    eval_dataset=tokenized_reviews[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 7.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(save_path)\n",
    "generator = pipeline('text-generation', finetuned_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = reviews['test'][0]['content']\n",
    "prompt = f'{inst} ### Review: {review} ### Reply:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ### Reply: Hi Matt. Please send us your feedback via the feedback form on our Support Forums. We appreciate your concern. üíú We're always on the look out for bugs, feedback and feature requests that arise with our app, and will be responsive to any potential issue that may arise. If you have any further concerns, feel free to reach us at help@xiaomi.com.sg.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate output method 1\n",
    "generator(prompt, max_length=len(review)+50)[0]['generated_text'][141+len(review):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### Reply: Hi Rika! I'm sorry for the inconvenience. We need to make sure that you get the correct bank card and are given the best deal on your order. We have to understand before you can use our mobile apps to access our services, so\n"
     ]
    }
   ],
   "source": [
    "# generate output method 2\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output = finetuned_model.generate(input_ids, max_new_tokens = 50)\n",
    "predicted_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(predicted_text[141+len(review):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(pred, actl):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    vector_matrix = count_vectorizer.fit_transform([pred[141:], actl[141:]])\n",
    "    cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "    return cosine_similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity: 0.15632927735967989\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_ls = []\n",
    "for review in reviews['test']:\n",
    "    content = review['content']\n",
    "    prompt = f'{inst} ### Review: {content} ### Reply:'\n",
    "    # pred = generator(prompt, max_length=len(content)+100)[0]['generated_text'][141+len(content):]\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = finetuned_model.generate(input_ids, max_new_tokens = 50)\n",
    "    predicted_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    pred = predicted_text[141+len(review):]\n",
    "    actl = review['replyContent']\n",
    "    cs = cos_sim(pred, actl)\n",
    "    cosine_similarity_ls.append(cs)\n",
    "\n",
    "print(f'Average cosine similarity: {np.mean(cosine_similarity_ls)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19611613513818407,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.18802535827258876,\n",
       " 0.2574253920840865,\n",
       " 0.16903085094570328,\n",
       " 0.11933359262635951,\n",
       " 0.0,\n",
       " 0.19802950859533489,\n",
       " 0.03580574370197164,\n",
       " 0.32025630761017426,\n",
       " 0.1507556722888818,\n",
       " 0.07207499701564471,\n",
       " 0.11821656093586509,\n",
       " 0.33351867298253507,\n",
       " 0.34782754811291194,\n",
       " 0.29958563516135256,\n",
       " 0.3205835717220036,\n",
       " 0.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
